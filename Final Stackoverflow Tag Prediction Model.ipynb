{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Stackoverflow Tag Prediction Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4MJvNL9vsaD"
      },
      "source": [
        "# Final Model For StackOverflow Tag Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWc9rdWOvCN7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from wordcloud import WordCloud\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VqNvrSOv3-K",
        "outputId": "6339d871-c1ba-4541-86aa-a02484fe2ed6"
      },
      "source": [
        "%%time\n",
        "## sample_500k is a sample from main dataset \n",
        "preprocess_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /preprocessed_3title_100k.csv\")\n",
        "preprocess_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 918 ms, sys: 220 ms, total: 1.14 s\n",
            "Wall time: 5.81 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "_6Nqe3Uav8j_",
        "outputId": "09e3a95a-54a2-4536-ab31-5fb61b47f792"
      },
      "source": [
        "preprocess_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>question</th>\n",
              "      <th>code</th>\n",
              "      <th>tags</th>\n",
              "      <th>word_count_before</th>\n",
              "      <th>word_count_after</th>\n",
              "      <th>is_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>gvim window path issu gvim window path issu gv...</td>\n",
              "      <td>['\\\\...\\\\gvim\\\\vim73\\n', '\\\\...\\\\gvim\\n', 'vim...</td>\n",
              "      <td>windows-7 windows-xp vim gvim</td>\n",
              "      <td>749</td>\n",
              "      <td>341</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>pass quotient via quotient map preserv topolog...</td>\n",
              "      <td>[]</td>\n",
              "      <td>general-topology</td>\n",
              "      <td>701</td>\n",
              "      <td>446</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>jqueri cycl function paramet jqueri cycl funct...</td>\n",
              "      <td>['$container.cycle(i, manualEffects[i]);', '$(...</td>\n",
              "      <td>jquery jquery-cycle</td>\n",
              "      <td>1083</td>\n",
              "      <td>211</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>updat problem listbox form fed queri updat pro...</td>\n",
              "      <td>[]</td>\n",
              "      <td>ms-access</td>\n",
              "      <td>368</td>\n",
              "      <td>223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>synergi conf listen synergi conf listen synerg...</td>\n",
              "      <td>['section: screens\\n    Roel-Desktop:\\n       ...</td>\n",
              "      <td>synergy</td>\n",
              "      <td>937</td>\n",
              "      <td>398</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... is_code\n",
              "0           0  ...       1\n",
              "1           1  ...       0\n",
              "2           2  ...       1\n",
              "3           3  ...       0\n",
              "4           4  ...       1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BNfmATJv87o"
      },
      "source": [
        "def text_splitter(text):\n",
        "    return text.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjsREg1Uv-y5"
      },
      "source": [
        "# binary='true' will give a binary vectorizer\n",
        "tag_vectorizer = CountVectorizer(tokenizer = text_splitter, binary=True)\n",
        "multi_label_y = tag_vectorizer.fit_transform(preprocess_data['tags'].values.astype(str))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90yIgqAJwBUn"
      },
      "source": [
        "# make sum column wise\n",
        "tag_column_sum = multi_label_y.sum(axis=0).tolist()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZRiyOqVwGDZ"
      },
      "source": [
        "# To select n number of top tags\n",
        "def select_top_tags(n):\n",
        "    \n",
        "    # To get sotred list (means: tags appear in maximum number of questions come first)\n",
        "    # top 10: [3711, 15246, 22934, 15324, 1054, 15713, 3720, 24481, 14905, 1897]\n",
        "    sorted_tags = sorted(range(len(tag_column_sum)), key=lambda i: tag_column_sum[i], reverse=True)\n",
        "    \n",
        "    # With this line of code we get tags in our columns which are come in most of the questions\n",
        "    # we will get shape: (999999, n)\n",
        "    multi_label_n_y = multi_label_y[:,sorted_tags[:n]]\n",
        "    return multi_label_n_y\n",
        "# \n",
        "def questions_covered_fn(n):\n",
        "    multi_label_n_y = select_top_tags(n)\n",
        "    \n",
        "    # This line will give us row wise sum of each row  [[1, 2],           [[3],\n",
        "    #                                                   [4, 3]]     to     [7]]\n",
        "    row_sum_array = multi_label_n_y.sum(axis=1)\n",
        "\n",
        "    # Counts the number of non-zero values in the array\n",
        "    return (np.count_nonzero(row_sum_array==0))\n",
        "# With this code we checking how much percent questions are explained by how many tags\n",
        "# Here we are starting from 500 because we think top 500 are most important tags we can't skip them\n",
        "questions_covered=[]\n",
        "total_tags=multi_label_y.shape[1]\n",
        "total_qs=preprocess_data.shape[0]\n",
        "for i in range(500, total_tags, 100):\n",
        "    questions_covered.append(np.round(((total_qs-questions_covered_fn(i))/total_qs)*100,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8_ywlcwwIKZ",
        "outputId": "4c7d7987-656b-4126-c5ca-addfdd519866"
      },
      "source": [
        "multi_label_n_y = select_top_tags(500)\n",
        "print(\"number of questions that are not covered :\", questions_covered_fn(5500),\"out of \", total_qs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of questions that are not covered : 896 out of  100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHo7jJiQwKJZ",
        "outputId": "f81d047a-05d7-4cdb-9034-a0f5f604483f"
      },
      "source": [
        "print(\"Number of tags in sample :\", multi_label_y.shape[1])\n",
        "print(\"number of tags taken :\", multi_label_n_y.shape[1],\"-->\",round((multi_label_n_y.shape[1]/multi_label_y.shape[1]),3)*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tags in sample : 18646\n",
            "number of tags taken : 500 --> 2.7 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEksF42nwMCF"
      },
      "source": [
        "total_size=preprocess_data.shape[0]\n",
        "train_size=int(0.80*total_size)\n",
        "\n",
        "x_train=preprocess_data.head(train_size)\n",
        "x_test=preprocess_data.tail(total_size - train_size)\n",
        "\n",
        "y_train = multi_label_n_y[0:train_size,:]\n",
        "y_test = multi_label_n_y[train_size:total_size,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqqv5NxwwU92"
      },
      "source": [
        "# To get new features with tfidf technique get 200000 features with upto 3-grams\n",
        "vectorizer = TfidfVectorizer(min_df=0.00009, max_features=200000, smooth_idf=True, norm=\"l2\", tokenizer = text_splitter, sublinear_tf=False, ngram_range=(1,3))\n",
        "# Apply this vectorizer only on question data column\n",
        "x_train_multi_label = vectorizer.fit_transform(x_train['question'])\n",
        "x_test_multi_label = vectorizer.transform(x_test['question'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ftdUwswWRh",
        "outputId": "beac8a46-fbf2-4a83-af31-8d50c72f513e"
      },
      "source": [
        "# Now check data shapes after featurization\n",
        "print(\"Dimensions of train data X:\",x_train_multi_label.shape, \"Y :\",y_train.shape)\n",
        "print(\"Dimensions of test data X:\",x_test_multi_label.shape,\"Y:\",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimensions of train data X: (80000, 91388) Y : (80000, 500)\n",
            "Dimensions of test data X: (20000, 91388) Y: (20000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-gQC_GxwYBO",
        "outputId": "66b38e67-ce3f-459c-a02c-49c86a4c3a6c"
      },
      "source": [
        "from joblib import dump\n",
        "dump(vectorizer, '/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /final_stackoverflow_tfidf_vectorizer.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /final_stackoverflow_tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f_I4bfWwhcA"
      },
      "source": [
        "classifier = OneVsRestClassifier(LogisticRegression(penalty='l1',solver='liblinear',C=20), n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lp76Wh2ZwrQC",
        "outputId": "a95313c9-7dc0-4f39-c9ed-feb358c11bea"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "classifier.fit(x_train_multi_label, y_train)\n",
        "print(\"Time it takes to run this :\",(time.time()-start)/60,\"minutes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time it takes to run this : 20.991809046268465 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gDidUT3zwvB6",
        "outputId": "bdccc9d7-a079-4495-e896-526c069981eb"
      },
      "source": [
        "dump(classifier, '/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /final_stackoverflow_logistic_regression.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /final_stackoverflow_logistic_regression.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XnL7ncWCw0z-",
        "outputId": "f9dec048-1134-4835-a10d-af554749407d"
      },
      "source": [
        "predictions = classifier.predict(x_test_multi_label)\n",
        "print(\"accuracy :\",metrics.accuracy_score(y_test,predictions))\n",
        "print(\"macro f1 score :\",metrics.f1_score(y_test, predictions, average = 'macro'))\n",
        "print(\"micro f1 scoore :\",metrics.f1_score(y_test, predictions, average = 'micro'))\n",
        "print(\"hamming loss :\",metrics.hamming_loss(y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.2146\n",
            "macro f1 score : 0.3730535292007937\n",
            "micro f1 scoore : 0.4901261475463972\n",
            "hamming loss : 0.003088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-FxUPBs3hFD"
      },
      "source": [
        "**Observations**\n",
        "* We get highest score with these parameters on 100k data points.\n",
        "* If we train our model with more data then we can get more micro f1 score. "
      ]
    }
  ]
}