{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM Model for model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NLC-Q5ccjpnX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybzJm07bpaEt",
    "outputId": "859fe492-b1bc-4fb7-b573-1734040e5e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 243 ms, total: 1.26 s\n",
      "Wall time: 3.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## sample_500k is a sample from main dataset \n",
    "preprocess_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /preprocessed_3title_100k.csv\")\n",
    "preprocess_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "hKB-EBeFrDvn",
    "outputId": "109168dc-7df3-4547-c888-10e629580560"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>code</th>\n",
       "      <th>tags</th>\n",
       "      <th>word_count_before</th>\n",
       "      <th>word_count_after</th>\n",
       "      <th>is_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gvim window path issu gvim window path issu gv...</td>\n",
       "      <td>['\\\\...\\\\gvim\\\\vim73\\n', '\\\\...\\\\gvim\\n', 'vim...</td>\n",
       "      <td>windows-7 windows-xp vim gvim</td>\n",
       "      <td>749</td>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pass quotient via quotient map preserv topolog...</td>\n",
       "      <td>[]</td>\n",
       "      <td>general-topology</td>\n",
       "      <td>701</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>jqueri cycl function paramet jqueri cycl funct...</td>\n",
       "      <td>['$container.cycle(i, manualEffects[i]);', '$(...</td>\n",
       "      <td>jquery jquery-cycle</td>\n",
       "      <td>1083</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>updat problem listbox form fed queri updat pro...</td>\n",
       "      <td>[]</td>\n",
       "      <td>ms-access</td>\n",
       "      <td>368</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>synergi conf listen synergi conf listen synerg...</td>\n",
       "      <td>['section: screens\\n    Roel-Desktop:\\n       ...</td>\n",
       "      <td>synergy</td>\n",
       "      <td>937</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ... is_code\n",
       "0           0  ...       1\n",
       "1           1  ...       0\n",
       "2           2  ...       1\n",
       "3           3  ...       0\n",
       "4           4  ...       1\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "maFUOrv8piay"
   },
   "outputs": [],
   "source": [
    "def text_splitter(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TO5BUgLMpiYU"
   },
   "outputs": [],
   "source": [
    "# binary='true' will give a binary vectorizer\n",
    "tag_vectorizer = CountVectorizer(tokenizer = text_splitter, binary=True)\n",
    "multi_label_y = tag_vectorizer.fit_transform(preprocess_data['tags'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X0OwaY-FpiVT"
   },
   "outputs": [],
   "source": [
    "# make sum column wise\n",
    "tag_column_sum = multi_label_y.sum(axis=0).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RW0287DLpiN1"
   },
   "outputs": [],
   "source": [
    "# To select n number of top tags\n",
    "def select_top_tags(n):\n",
    "    \n",
    "    # To get sotred list (means: tags appear in maximum number of questions come first)\n",
    "    # top 10: [3711, 15246, 22934, 15324, 1054, 15713, 3720, 24481, 14905, 1897]\n",
    "    sorted_tags = sorted(range(len(tag_column_sum)), key=lambda i: tag_column_sum[i], reverse=True)\n",
    "    \n",
    "    # With this line of code we get tags in our columns which are come in most of the questions\n",
    "    # we will get shape: (999999, n)\n",
    "    multi_label_n_y = multi_label_y[:,sorted_tags[:n]]\n",
    "    return multi_label_n_y\n",
    "# \n",
    "def questions_covered_fn(n):\n",
    "    multi_label_n_y = select_top_tags(n)\n",
    "    \n",
    "    # This line will give us row wise sum of each row  [[1, 2],           [[3],\n",
    "    #                                                   [4, 3]]     to     [7]]\n",
    "    row_sum_array = multi_label_n_y.sum(axis=1)\n",
    "\n",
    "    # Counts the number of non-zero values in the array\n",
    "    return (np.count_nonzero(row_sum_array==0))\n",
    "# With this code we checking how much percent questions are explained by how many tags\n",
    "# Here we are starting from 500 because we think top 500 are most important tags we can't skip them\n",
    "questions_covered=[]\n",
    "total_tags=multi_label_y.shape[1]\n",
    "total_qs=preprocess_data.shape[0]\n",
    "for i in range(500, total_tags, 100):\n",
    "    questions_covered.append(np.round(((total_qs-questions_covered_fn(i))/total_qs)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzcxKHI7p06r",
    "outputId": "51665d11-964a-4566-c99d-10590c3212ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of questions that are not covered : 896 out of  100000\n"
     ]
    }
   ],
   "source": [
    "multi_label_n_y = select_top_tags(500)\n",
    "print(\"number of questions that are not covered :\", questions_covered_fn(5500),\"out of \", total_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__bsrlppp02Q",
    "outputId": "5f1ce5df-36b2-4b99-df5c-ca415dd6b67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags in sample : 18646\n",
      "number of tags taken : 500 --> 2.7 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tags in sample :\", multi_label_y.shape[1])\n",
    "print(\"number of tags taken :\", multi_label_n_y.shape[1],\"-->\",round((multi_label_n_y.shape[1]/multi_label_y.shape[1]),3)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "p9hMtVnkp0zu"
   },
   "outputs": [],
   "source": [
    "total_size=preprocess_data.shape[0]\n",
    "train_size=int(0.80*total_size)\n",
    "\n",
    "x_train=preprocess_data.head(train_size)\n",
    "x_test=preprocess_data.tail(total_size - train_size)\n",
    "\n",
    "y_train = multi_label_n_y[0:train_size,:]\n",
    "y_test = multi_label_n_y[train_size:total_size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Prtbt2v-p0w3",
    "outputId": "8a0fc490-078b-45de-def1-0583b931552b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.6 s, sys: 2.43 s, total: 56 s\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# To get new features with tfidf technique get 200000 features with upto 3-grams\n",
    "vectorizer = TfidfVectorizer(min_df=0.00009, max_features=200000, smooth_idf=True, norm=\"l2\", tokenizer = text_splitter, sublinear_tf=False, ngram_range=(1,3))\n",
    "# Apply this vectorizer only on question data column\n",
    "x_train_multi_label = vectorizer.fit_transform(x_train['question'])\n",
    "x_test_multi_label = vectorizer.transform(x_test['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDB26LyJp8nJ",
    "outputId": "60d3b8fb-7c6b-40a2-d66a-6253866f673c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (80000, 91388) Y : (80000, 500)\n",
      "Dimensions of test data X: (20000, 91388) Y: (20000, 500)\n"
     ]
    }
   ],
   "source": [
    "# Now check data shapes after featurization\n",
    "print(\"Dimensions of train data X:\",x_train_multi_label.shape, \"Y :\",y_train.shape)\n",
    "print(\"Dimensions of test data X:\",x_test_multi_label.shape,\"Y:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksopJMi6p8k0",
    "outputId": "5be07b63-50fb-4895-d22d-7bdc649d2e90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /stackoverflow_tfidf_vectorizer_liner_svm__4grams_100k.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(vectorizer, '/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /stackoverflow_tfidf_vectorizer_liner_svm__4grams_100k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "dtwgLamfp8iC"
   },
   "outputs": [],
   "source": [
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=0.00001, penalty='l1'), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_fN2p0Rp8fT",
    "outputId": "1c01d8f3-8f05-4a71-868f-842cbf42dd21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time it takes to run this : 2.943255400657654 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "classifier.fit(x_train_multi_label, y_train)\n",
    "print(\"Time it takes to run this :\",(time.time()-start)/60,\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_u8AboZqO0T",
    "outputId": "be2dd57d-cf0a-4670-e83c-5db1f42b57dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /stackoverflow_model_liner_svm_4grams_100k.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(classifier, '/content/drive/MyDrive/Colab Notebooks/Stack overflow Tag /stackoverflow_model_liner_svm_4grams_100k.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHYCcw8wqTkM",
    "outputId": "1dabf712-ad6d-47e8-9dae-c763d3611cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.2473\n",
      "macro f1 score : 0.29326674885905196\n",
      "micro f1 scoore : 0.47650955021565006\n",
      "hamming loss : 0.0027188\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test_multi_label)\n",
    "print(\"accuracy :\",metrics.accuracy_score(y_test,predictions))\n",
    "print(\"macro f1 score :\",metrics.f1_score(y_test, predictions, average = 'macro'))\n",
    "print(\"micro f1 scoore :\",metrics.f1_score(y_test, predictions, average = 'micro'))\n",
    "print(\"hamming loss :\",metrics.hamming_loss(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "LfE3NvR5qZeY"
   },
   "outputs": [],
   "source": [
    "report = metrics.classification_report(y_test, predictions, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv(\"/content/report_liner_svm_100k.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic regression for tags with 4 grams.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
